---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: '0.9'
    jupytext_version: 1.5.0
kernelspec:
  display_name: Python 3
  language: python
  name: python3
---

# The Kolmogorov Forward Equation



## Overview

In this lecture we approach continuous time Markov chains from a more
analytical perspective.

The emphasis will be on describing distribution flows through vector-valued
differential equations.

These distribution flows show how the time $t$ distribution associated with a
given Markov chain $(X_t)$ changes over time.

Distribution flows will be identified with initial value problems generated by autonomous linear ordinary differential equations (ODEs) in vector space.

We will see that the solutions of these flows are described by Markov semigroups.

This leads us back to the theory we have already constructed -- some care will
be taken to clarify all the connections.

In order to avoid being distracted by technicalities, we continue to defer our
treatment of infinite state spaces, assuming throughout this lecture that $|S|
= n$.

As before, $\mathcal D$ is the set of all distributions on $S$.

We will use the following imports

```{code-cell} ipython3
import numpy as np
import scipy as sp
import matplotlib.pyplot as plt
import quantecon as qe
from numba import njit
from scipy.linalg import expm

from matplotlib import cm
from mpl_toolkits.mplot3d import Axes3D
from mpl_toolkits.mplot3d.art3d import Poly3DCollection
```

## From Difference Equations to ODEs

{ref}`Previously <invdistflows>` we generated this figure, which shows how distributions evolve over time for the inventory model under a certain parameterization:

```{glue:figure} flow_fig
:name: "flow_fig"

Probability flows for the inventory model.
```

(Hot colors indicate early dates and cool colors denote later dates.)

We also learned how this flow can be described, at least indirectly,
through the Kolmogorov backward equation, which is an ODE.

In this section we examine distribution flows and their connection to 
ODEs and continuous time Markov chains more systematically.

Although our initial discussion appears to be orthogonal to what has come
before, the connections and relationships will soon become clear.


### Review of the Discrete Time Case

Let $(X_t)$ be a discrete time Markov chain with Markov matrix $P$.

{ref}`Recall that <finstatediscretemc>`, in the discrete time case, the distribution $\psi_t$ of $X_t$ updates according to 

$$
    \psi_{t+1} = \psi_t P, 
    \qquad \psi_0 \text{ a given element of } \mathcal D,
$$

where distributions are understood as row vectors.

Here's a visualization for the case $|S|=3$, so that $\mathcal D$ is the unit
simplex in $\mathbb R^3$.

The initial condition is `` (0, 0, 1)`` and the Markov matrix is

```{code-cell} ipython3
P = ((0.9, 0.1, 0.0),
     (0.4, 0.4, 0.2),
     (0.1, 0.1, 0.8))
```

```{code-cell} ipython3
:tags: [hide-input]

def unit_simplex(angle):
    
    fig = plt.figure(figsize=(8, 6))
    ax = fig.add_subplot(111, projection='3d')

    vtx = [[0, 0, 1],
           [0, 1, 0], 
           [1, 0, 0]]
    
    tri = Poly3DCollection([vtx], color='darkblue', alpha=0.3)
    tri.set_facecolor([0.5, 0.5, 1])
    ax.add_collection3d(tri)

    ax.set(xlim=(0, 1), ylim=(0, 1), zlim=(0, 1), 
           xticks=(1,), yticks=(1,), zticks=(1,))

    ax.set_xticklabels(['$(1, 0, 0)$'], fontsize=12)
    ax.set_yticklabels(['$(0, 1, 0)$'], fontsize=12)
    ax.set_zticklabels(['$(0, 0, 1)$'], fontsize=12)

    ax.xaxis.majorTicks[0].set_pad(15)
    ax.yaxis.majorTicks[0].set_pad(15)
    ax.zaxis.majorTicks[0].set_pad(35)

    ax.view_init(30, angle)

    # Move axis to origin
    ax.xaxis._axinfo['juggled'] = (0, 0, 0)
    ax.yaxis._axinfo['juggled'] = (1, 1, 1)
    ax.zaxis._axinfo['juggled'] = (2, 2, 0)
    
    ax.grid(False)
    
    return ax


def convergence_plot(ψ, n=14, angle=50):

    ax = unit_simplex(angle)

    P = ((0.9, 0.1, 0.0),
         (0.4, 0.4, 0.2),
         (0.1, 0.1, 0.8))
    
    P = np.array(P)
    colors = cm.jet_r(np.linspace(0.0, 1, n))

    x_vals, y_vals, z_vals = [], [], []
    for t in range(n):
        x_vals.append(ψ[0])
        y_vals.append(ψ[1])
        z_vals.append(ψ[2])
        ψ = ψ @ P

    ax.scatter(x_vals, y_vals, z_vals, c=colors, s=50, alpha=0.7, depthshade=False)

    return ψ

ψ = convergence_plot((0, 0, 1))

plt.show()
```

There's a sense in which a discrete time Markov chain "is" a homogeneous
linear difference equation in distribution space.

To clarify this, suppose we 
take $G$ to be a linear map from $\mathcal D$ to itself and
write down the difference equation 

$$
    \psi_{t+1} = G(\psi_t)
    \quad \text{with } \psi_0 \in \mathcal D \text{ given}.
$$ (gdiff)

Because $G$ is a linear map from a finite dimensional space to itself, it can
be represented by a matrix.

Moreover, a matrix $P$ is a Markov matrix if and only if $\psi \mapsto
\psi P$ sends $\mathcal D$ into itself (check it if you haven't already).

So, under the stated conditions, our difference equation {eq}`gdiff` uniquely
identifies a Markov matrix, along with an initial condition $\psi_0$.

Together, these objects identify the joint distribution of a discrete time Markov chain, as {ref}`previously described <jdfin>`.


### Shifting to Continuous Time

We have just argued that a discrete time Markov chain "is" a linear difference
equation evolving in $\mathcal D$.

This strongly suggests that a continuous time Markov chain "is" a linear ODE
evolving in $\mathcal D$.

In this scenario,

1. distributions update according to an automous linear differential equation and
2. the vector field is such that trajectories remain in $\mathcal D$.

This intuition is correct and highly beneficial.  

The rest of the lecture maps out the main ideas.



## ODEs in Distribution Space

Consider linear differential equation given by 

$$
    \psi_t' = \psi_t Q, 
    \qquad \psi_0 \text{ a given element of } \mathcal D,
$$ (ode_mc)

where 

* $Q$ is an $n \times n$ matrix,
* distributions are again understood as row vectors, and
* derivatives are taken element by element, so that

$$
    \psi_t' =
    \begin{pmatrix}
        \frac{d}{dt} \psi_t(1) &
        \cdots &
        \frac{d}{dt} \psi_t(n)
    \end{pmatrix}
$$

### Solutions to Linear Vector ODEs

Using the matrix exponential, the unique solution to the initial value problem
{eq}`ode_mc` is

$$
    \psi_t = \psi_0 P_t 
    \quad \text{where } P_t := e^{tQ}
$$ (cmc_sol)

To check that {eq}`cmc_sol` is a solution, we use {eq}`expoderiv` again to get

$$
    \frac{d}{d t} P_t =  Q e^{tQ} = e^{tQ} Q 
$$

The first equality can be written as $P_t' =  Q P_t$ and this is just 
the {doc}`Kolmogorov backward equation <kolmogorov_bwd>`.  

The second equality can be written as 

$$
    P_t' = P_t Q 
$$

and is called the **Kolmogorov forward equation**.

Applying the Kolmogorov forward equation, we obtain

$$
    \frac{d}{d t} \psi_t 
    = \frac{d}{d t} \psi_0 P_t 
    = \psi_0 \frac{d}{d t} P_t 
    = \psi_0 P_t Q
    = \psi_t Q
$$

This confirms that {eq}`cmc_sol` solves {eq}`ode_mc`.


Here's an example of three distribution flows with dynamics generated  by {eq}`ode_mc`,  one starting from each vertex.

The code uses {eq}`cmc_sol` with matrix $Q$ given by 

```{code-cell} ipython3
Q = ((-3, 2, 1),
     (3, -5, 2),
     (4, 6, -10))
```

```{code-cell} ipython3
:tags: [hide-input]

Q = np.array(Q)
ψ_00 = np.array((0.01, 0.01, 0.99))
ψ_01 = np.array((0.01, 0.99, 0.01))
ψ_02 = np.array((0.99, 0.01, 0.01))

ax = unit_simplex(angle=50)    

def flow_plot(ψ, h=0.001, n=400, angle=50):
    colors = cm.jet_r(np.linspace(0.0, 1, n))

    x_vals, y_vals, z_vals = [], [], []
    for t in range(n):
        x_vals.append(ψ[0])
        y_vals.append(ψ[1])
        z_vals.append(ψ[2])
        ψ = ψ @ expm(h * Q)

    ax.scatter(x_vals, y_vals, z_vals, c=colors, s=20, alpha=0.2, depthshade=False)

flow_plot(ψ_00)
flow_plot(ψ_01)
flow_plot(ψ_02)

plt.show()
```

(Distributions cool over time, so initial conditions are hot colors.)

### Forwards vs Backwards Equations

As the above discussion shows, we can take the Kolmogorov forward equation
$P_t' = P_t Q$ and premultiply by any distribution $\psi_0$ to get the
distribution ODE $\psi'_t = \psi_t Q$.

In this sense, we can understand the Kolmogorov forward equation as pushing
distributions forward in time.


Analogously, we can take the Kolmogorov backward equation
$P_t' = Q P_t$ and postmultiply by any vector $h$ to get 

$$
    (P_t h)' = Q P_t h
$$

Recalling that $(P_t h)(x) = \mathbb E [ h(X_t) \,|\, X_0 = x]$, this vector
ODE tells us how expectations evolve, conditioning backward to time zero.

Both the forward and the backward equations uniquely pin down the same solution 
$P_t = e^{tQ}$.


### Matrix- vs Vector-Valued ODEs

The ODE $\psi'_t = \psi_t Q$ is sometimes called the
**Fokker--Planck equation** (although this terminology is most commonly used
in the context of diffusions).

It is a vector-valued ODE that describes the evolution of a particular
distribution path.

By comparison, the Kolmogorov forward equation is (like the backward equation)
a differential equation in matrices.

(And matrices are really maps, that send vectors into vectors.)

Operating at this level is less intuitive and more abstract than working with the
Fokker--Planck equation.

But, in the end, the object that we want to describe is a the Markov
semigroup.

The Kolmogorov forward and backward equations are the ODEs that define
this fundamental object.





### Preserving Distributions


In the simulation above, $Q$ was chosen with some care, so that the flow
remains in $\mathcal D$.

What are the exact properties we require on $Q$ such that $\psi_t$ is always
in $\mathcal D$?

This is an important question, because we are setting up an exact
correspondence between linear ODEs that evolve in $\mathcal D$ and continuous
time Markov chains.

Recall that the linear update rule $\psi \mapsto \psi P$ is invariant on
$\mathcal D$ if and only if $P$ is a Markov matrix.

So now we can rephrase our key question regarding invariance on $\mathcal D$:

What properties do we need to impose on $Q$ so that $P_t = e^{tQ}$ is a Markov matrix
for all $t$?

A square matrix $Q$ is called an **intensity matrix** if $Q$ has zero row
sums and $Q(x, y) \geq 0$ whenever $x \not= y$.

(Some authors call this a transition rate matrix or a $Q$ matrix.)

Having zero row sums can be expressed as $Q \mathbb 1 = 0$ where $\mathbb 1$
is a column vector of ones.

As a small exercise, you can check that the following is true

$$
    Q \text{ has zero row sums }
    \iff
    Q^k \mathbb 1 = 0 \text{ for all } k \geq 1
$$ (zrsnec)

**Theorem** If $Q$ is an $n \times n$ matrix and $P_t := e^{tQ}$, then the
following statements are equivalent:

1. $P_t$ is a Markov matrix for all $t$.
1. $Q$ is an intensity matrix.

*Proof:*  Suppose first that $Q$ is an intensity matrix and set $P_t =
e^{tQ}$ for all $t$.

By the definition of the exponential function, for all $t \geq 0$,

$$
    P_t \mathbb 1 = \mathbb 1 + tQ \mathbb 1 + \frac{1}{2!} t^2 Q^2 \mathbb 1 + \cdots
$$

From {eq}`zrsnec`, we see that $P_t$ has unit row sums.

In addition, we can use the definition of the matrix exponential to obtain,
 for any $x, y$ and $t \geq 0$,

$$
    P_t(x, y) = \mathbb 1\{x = y\} + t Q(x, y) + o(t)
$$ (otp)

This implies that both off-diagonal and on-diagonal elements of $P_t$ are nonnegative for all $t$ in a neighborhood of zero.

Nonnegativity extends to arbitrary $t$ from the semigroup property and the fact that
products of nonnegative matrices are nonnegative.

Hence $P_t$ is a Markov matrix.

Regarding the converse implication, suppose that $P_t = e^{tQ}$ is a Markov
matrix for all $t$.

Because $P_t$ has unit row sums and differentiation is linear, 
we can employ the Kolmogorov backward equation to obtain

$$
    Q  \mathbb 1
      = Q P_t \mathbb 1
      = \left( \frac{d}{d t} P_t \right) \mathbb 1
      = \frac{d}{d t} (P_t \mathbb 1)
      = \frac{d}{d t} \mathbb 1
      = 0
$$

Hence $Q$ has zero row sums.

Moreover, in view of {eq}`otp`, the off diagonal elements of $Q$ must be positive.

Hence $Q$ is a intensity matrix.



## Back to the Inventory Example

Let's return to the inventory example we discussed in previous lectures.

Recall that, in the case where the jump rate is allowed to vary with the
state, the semigroup is given by 

$$ 
    P_t = e^{tQ}
    \quad \text{where} \quad
    Q(x, y) := \lambda(x) (K(x, y) - I(x, y))
$$

Here $K$ is the jump chain Markov matrix and $\lambda(x)$ is the jump
rate at $x$.

In light of the preceding analysis, we can differentiate to obtain the
Kolmogorov forward equation $P_t' = P_t Q$.

Hence $Q(x, y) = \lambda(x) (K(x, y) - I(x, y))$ describes the rate at which
probability mass flows from $x$ to $y$.

(We will make this clearer later on.)

We can also premultiply by $\psi_0 \in \mathcal D$ to get $\psi_t' = \psi_t
Q$, which is the Fokker--Planck equation.

Hence it's clear that $Q$ corresponds to the intensity matrix for this
semigroup.

(You can easily check that it satisfies the definition of an intensity matrix.)


## Exercises

### Exercise 1

Let $(P_t)$ be a Markov semigroup and let

$$ 
    Q := P'_0 = \lim_{h \downarrow 0} \frac{P_h - I}{h}
$$ (genfl)

Assuming that this limit exists, and hence $Q$ is well-defined, show that

$$
    P'_t = P_t Q
    \quad \text{and} \quad
    P'_t = Q P_t 
$$

both hold. (These are the Kolmogorov forward and backward equations.)


### Exercise 2

Recall {ref}`our model <sdji>` of jump chains with state-dependent jump
intensities given by rate function $x \mapsto \lambda(x)$.

After a wait time with exponential rate $\lambda(x) \in (0, \infty)$, the
state transitions from $x$ to $y$ with probability $K(x,y)$.

We found that the associated semigroup $(P_t)$ satisfies the Kolmogorov
backward equation $P'_t = Q P_t$ with 

$$
    Q(x, y) := \lambda(x) (K(x, y) - I(x, y))
$$ (qeqagain)

Show that $Q$ is an intensity matrix and that {eq}`genfl` holds.


## Solutions

### Solution to Exercise 1

Let $(P_t)$ be a Markov semigroup and let $Q$ be as defined in the statement
of the exercise.

Fix $t \geq 0$ and $h > 0$. 

Combining the semigroup property and linearity with the restriction $P_0 = I$, we get

$$
    \frac{P_{t+h} - P_t}{h}  
    = \frac{P_t P_h - P_t}{h}  
    = \frac{P_t (P_h - I)}{h}  
$$

Taking $h \downarrow 0$ and using the definition of $Q$ gives $P_t' = P_t Q$,
which is the Kolmogorov forward equation.

For the backward equation we observe that 

$$
    \frac{P_{t+h} - P_t}{h}  
    = \frac{P_h P_t - P_t}{h}  
    = \frac{(P_h - I) P_t}{h}  
$$

also holds.  Taking $h \downarrow 0$ gives the Kolmogorov backward equation.



### Solution to Exercise 2

Let $Q$ be as defined in {eq}`qeqagain`.

We need to show that $Q$ is nonnegative off the diagonal and has zero row
sums.

The first assertion is immediate from nonnegativity of $K$ and $\lambda$.

For the second, we use the fact that $K$ is a Markov matrix, so that, with $1$
as a column vector of ones,

$$
    Q 1 
    = \lambda (K 1 - 1)
    = \lambda (1 - 1)
    = 0
$$
